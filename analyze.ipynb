{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import ray\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision as tv\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "from src.common.atari_wrappers import wrap_deepmind, make_atari\n",
    "from src.common.utils import LinearSchedule, DataLoaderX, DataPrefetcher, ReplayDataset\n",
    "from src.common.vec_env import ShmemVecEnv, VecEnvWrapper, DummyVecEnv\n",
    "from src.agents.model import NatureCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "2020-08-03 05:52:45,041\tINFO resource_spec.py:212 -- Starting Ray with 210.5 GiB memory available for workers and up to 94.21 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-08-03 05:52:45,187\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-08-03 05:52:45,431\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-08-03 05:52:45,701\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.1.154',\n 'raylet_ip_address': '192.168.1.154',\n 'redis_address': '192.168.1.154:27136',\n 'object_store_address': '/tmp/ray/session_2020-08-03_05-52-45_038199_24917/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2020-08-03_05-52-45_038199_24917/sockets/raylet',\n 'webui_url': 'localhost:8266',\n 'session_dir': '/tmp/ray/session_2020-08-03_05-52-45_038199_24917'}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "game = \"Breakout\"\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "num_env = 8\n",
    "num_actors = 32\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_cpus = mp.cpu_count()\n",
    "total_steps = int(1e7)\n",
    "epoches = 10\n",
    "update_per_data = 8\n",
    "replay_size = int(1e6)\n",
    "exploration_ratio = 0.1\n",
    "discount = 0.99\n",
    "batch_size = 512\n",
    "base_batch_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "target_net_update_freq = 250\n",
    "exploration_ratio = 0.2\n",
    "steps_per_epoch = total_steps // epoches \n",
    "replay = deque(maxlen=replay_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-97d82b5be622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mepsilon_schedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSchedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexploration_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNatureCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "def make_env(game, episode_life=True, clip_rewards=True):\n",
    "    env = make_atari(f'{game}NoFrameskip-v4')\n",
    "    env = wrap_deepmind(env, episode_life=episode_life, clip_rewards=clip_rewards, frame_stack=True, scale=False, transpose_image=True)\n",
    "    return env\n",
    "\n",
    "test_env = make_env(game)\n",
    "state_shape = test_env.observation_space.shape\n",
    "action_shape = test_env.action_space.n\n",
    "epsilon_schedule = LinearSchedule(1.0, 0.01, int(epoches * exploration_ratio)) \n",
    "\n",
    "model = NatureCNN(state_shape[0], action_shape).to(device)\n",
    "model_target = copy.deepcopy(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ckpt/e2.pth')['model'])\n",
    "model_target = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sampler(rank, epsilon, state_dict):\n",
    "    envs = ShmemVecEnv([lambda: make_env(game) for _ in range(num_env)], context='fork')\n",
    "    steps = steps_per_epoch // (num_env * num_actors)\n",
    "    R = np.zeros(num_env)\n",
    "    Rs, Qs = [], []\n",
    "    local_replay = deque(maxlen=replay_size)\n",
    "    model = NatureCNN(state_shape[0], action_shape)\n",
    "    model.load_state_dict(state_dict)\n",
    "    obs = envs.reset()\n",
    "    tic = time.time()\n",
    "    for step in range(steps):\n",
    "        action_random = np.random.randint(0, action_shape, num_env)\n",
    "        st = torch.from_numpy(np.array(obs)).float() / 255.0\n",
    "        qs = model(st)\n",
    "        qs_max, qs_argmax = qs.max(dim=-1)\n",
    "        action_greedy = qs_argmax.tolist()\n",
    "        Qs.append(qs_max.mean().item())\n",
    "        action = [act_grd if p > epsilon else act_rnd for p, act_rnd, act_grd in zip(np.random.rand(num_env), action_random, action_greedy)]\n",
    "\n",
    "        obs_next, reward, done, info = envs.step(action)\n",
    "        for entry in zip(obs, action, reward, obs_next, done):\n",
    "            local_replay.append(entry)\n",
    "        obs = obs_next\n",
    "        R += np.array(reward)\n",
    "        for idx, d in enumerate(done):\n",
    "            if d:\n",
    "                Rs.append(R[idx])\n",
    "                R[idx] = 0\n",
    "    toc = time.time()\n",
    "    envs.close()\n",
    "    print(f\"Rank {rank}, Data Collection Time: {toc - tic}, Speed {steps_per_epoch / (toc - tic)}\")\n",
    "    return local_replay, Rs, Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# model = torch.nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "# model_target = torch.nn.DataParallel(model_target, device_ids=[0,1,2,3])\n",
    "# data = torch.randn(batch_size, 4, 84, 84).cuda(), torch.rand(batch_size).mul(4.0).long().cuda(), torch.randn(batch_size).cuda(), torch.randn(batch_size, 4, 84, 84).cuda(), torch.randn(batch_size).cuda()\n",
    "\n",
    "def train(model, model_target):\n",
    "    dataset = ReplayDataset(replay)\n",
    "    dataloader = DataLoaderX(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    prefetcher = DataPrefetcher(dataloader, device)\n",
    "    steps = (steps_per_epoch ) // batch_size\n",
    "    Ls = []\n",
    "    model.cuda()\n",
    "    tic = time.time()\n",
    "    for step in range(steps):\n",
    "        try:\n",
    "            data = prefetcher.next()\n",
    "        except:\n",
    "            prefetcher = DataPrefetcher(dataloader, device)\n",
    "            data = prefetcher.next()\n",
    "\n",
    "        states, actions, rewards, next_states, terminals = data\n",
    "        states = states.float() / 255.0\n",
    "        next_states = next_states.float() / 255.0\n",
    "        actions = actions.long()\n",
    "        terminals = terminals.float()\n",
    "        rewards = rewards.float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_next = model_target(next_states)\n",
    "            q_next_online = model(next_states)\n",
    "            q_next = q_next.gather(1, q_next_online.argmax(dim=-1).unsqueeze(-1)).squeeze(-1)\n",
    "            q_target = rewards + discount * (1 - terminals) * q_next\n",
    "\n",
    "        q = model(states).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "        loss = F.smooth_l1_loss(q, q_target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        Ls.append(loss.item())\n",
    "        if step % target_net_update_freq == 0:\n",
    "            model_target.load_state_dict(model.state_dict())\n",
    "    toc = time.time()\n",
    "    print(\"Loss\", np.mean(Ls), np.std(Ls), np.max(Ls))\n",
    "    print(\"Epoch Time\", toc - tic)\n",
    "    return model, model_target, Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    tic = time.time()\n",
    "    num_test_envs = 8\n",
    "    test_envs = ShmemVecEnv([lambda: make_env(game) for _ in range(num_test_envs)], context='fork')\n",
    "\n",
    "    E = 0\n",
    "    R = np.zeros(num_test_envs)\n",
    "    obs = test_envs.reset()\n",
    "    Rs = []\n",
    "    while True:\n",
    "        obs = torch.from_numpy(np.array(obs)).to(device).float().div(255.0)\n",
    "        action = model(obs).argmax(dim=-1).tolist()\n",
    "        obs_next, reward, done, info = test_envs.step(action)\n",
    "        obs = obs_next\n",
    "        R += np.array(reward)\n",
    "        for idx, d in enumerate(done):\n",
    "            if d:\n",
    "                Rs.append(R[idx])\n",
    "                R[idx] = 0\n",
    "                E += 1\n",
    "        if E > 300:\n",
    "            break\n",
    "    test_envs.close()\n",
    "    toc = time.time()\n",
    "    print(\"Test Reward\", np.mean(Rs), np.std(Rs), np.max(Rs))\n",
    "    print(\"Epoch Time\", toc - tic)\n",
    "    return Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "LLs, QQs, RRs, TRRs = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Sampling\n",
    "epoch = 2\n",
    "epsilon = 0.1\n",
    "print(\"Epoch\", epoch, \"Epsilon\", epsilon)\n",
    "datas = ray.get([sampler.remote(rank, epsilon, model.cpu().state_dict()) for rank in range(num_actors)])\n",
    "Rs, Qs = [], []\n",
    "for lp, rs, qs in datas:\n",
    "    replay.extend(lp)\n",
    "    Rs += rs\n",
    "    Qs += qs\n",
    "    del lp\n",
    "    del rs\n",
    "    del qs\n",
    "print(\"Training Reward\", np.mean(Rs), np.std(Rs), np.max(Rs))\n",
    "print(\"Training Q\", np.mean(Qs), np.std(Qs), np.max(Qs))\n",
    "RRs += Rs\n",
    "QQs += Qs\n",
    "del datas\n",
    "print(\"=\" * 100)\n",
    "print(\" \" * 100)\n",
    "\n",
    "for epoch in range(1):\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)\n",
    "    print(\" \" * 100)\n",
    "\n",
    "    \n",
    "    for step in range(15):\n",
    "        ## Training\n",
    "        model, model_target, Ls = train(model, model_target)\n",
    "        LLs += Ls\n",
    "        ## Testing\n",
    "        TRs = test(model)\n",
    "        TRRs += TRs\n",
    "    # torch.save({'model': model.state_dict(), 'loss': LLs, 'Train EPR': RRs, 'Test EPR': TRRs}, f'ckpt/e{epoch}.pth')\n",
    "    print(\" \" * 100)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict(), 'loss': LLs, 'Train EPR': RRs, 'Test EPR': TRRs}, f'ckpt/e{2}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12, 9), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "len(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(savgol_filter(LLs, 11, 2)[500:])\n",
    "plt.plot(LLs[20000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(savgol_filter(RRss + RRs, 101, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(savgol_filter(QQs, 101, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(savgol_filter(TTRss + TRRs, 101, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "TTRss = torch.load('ckpt/e1.pth')['Test EPR']\n",
    "LLss = torch.load('ckpt/e1.pth')['loss']\n",
    "RRss = torch.load('ckpt/e1.pth')['Train EPR'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}