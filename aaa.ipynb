{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import scipy\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import ray\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision as tv\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "\n",
    "from src.common.atari_wrappers import wrap_deepmind, make_atari\n",
    "from src.common.utils import LinearSchedule, DataLoaderX, DataPrefetcher, ReplayDataset\n",
    "from src.common.vec_env import ShmemVecEnv, VecEnvWrapper, DummyVecEnv\n",
    "from src.agents.model import NatureCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "game = \"Breakout\"\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "num_env = 8\n",
    "num_actors = 32\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_cpus = mp.cpu_count()\n",
    "total_steps = int(1e7)\n",
    "epoches = 10\n",
    "update_per_data = 8\n",
    "replay_size = int(1e6)\n",
    "exploration_ratio = 0.1\n",
    "discount = 0.99\n",
    "batch_size = 512\n",
    "base_batch_size = 32\n",
    "lr = 1e-3\n",
    "\n",
    "target_net_update_freq = 250\n",
    "exploration_ratio = 0.2\n",
    "steps_per_epoch = total_steps // epoches \n",
    "replay = deque(maxlen=replay_size)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_env(game, episode_life=True, clip_rewards=True):\n",
    "    env = make_atari(f'{game}NoFrameskip-v4')\n",
    "    env = wrap_deepmind(env, episode_life=episode_life, clip_rewards=clip_rewards, frame_stack=True, scale=False, transpose_image=True)\n",
    "    return env"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Runner(object):\n",
    "    \"\"\"Actor object to start running simulation on workers.\n",
    "        Gradient computation is also executed on this object.\"\"\"\n",
    "    def __init__(self, env_name, actor_id):\n",
    "        # starts simulation environment, policy, and thread.\n",
    "        # Thread will continuously interact with the simulation environment\n",
    "        env = make_atari(env_name)\n",
    "        self.id = actor_id\n",
    "        self.policy = NatureCNN(self.env.observation_space.shape[0], self.env.action_space.n)\n",
    "        self.runner = RunnerThread(env, self.policy, 20)\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        # starts the simulation thread\n",
    "        self.runner.start_runner()\n",
    "\n",
    "    def pull_batch_from_queue(self):\n",
    "        # Implementation details removed - gets partial rollout from queue\n",
    "        return rollout\n",
    "\n",
    "    def compute_gradient(self, params):\n",
    "        self.policy.set_weights(params)\n",
    "        rollout = self.pull_batch_from_queue()\n",
    "        batch = process_rollout(rollout, gamma=0.99, lambda_=1.0)\n",
    "        gradient = self.policy.compute_gradients(batch)\n",
    "        info = {\"id\": self.id,\n",
    "                \"size\": len(batch.a)}\n",
    "        return gradient, info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "\n",
    "def train(num_workers, env_name=\"PongDeterministic-v4\"):\n",
    "    # Setup a copy of the environment\n",
    "    # Instantiate a copy of the policy - mainly used as a placeholder\n",
    "    env = create_env(env_name, None, None)\n",
    "    policy = LSTMPolicy(env.observation_space.shape, env.action_space.n, 0)\n",
    "    obs = 0\n",
    "\n",
    "    # Start simulations on actors\n",
    "    agents = [Runner.remote(env_name, i) for i in range(num_workers)]\n",
    "\n",
    "    # Start gradient calculation tasks on each actor\n",
    "    parameters = policy.get_weights()\n",
    "    gradient_list = [agent.compute_gradient.remote(parameters) for agent in agents]\n",
    "\n",
    "    while True: # Replace with your termination condition\n",
    "        # wait for some gradient to be computed - unblock as soon as the earliest arrives\n",
    "        done_id, gradient_list = ray.wait(gradient_list)\n",
    "\n",
    "        # get the results of the task from the object store\n",
    "        gradient, info = ray.get(done_id)[0]\n",
    "        obs += info[\"size\"]\n",
    "\n",
    "        # apply update, get the weights from the model, start a new task on the same actor object\n",
    "        policy.apply_gradients(gradient)\n",
    "        parameters = policy.get_weights()\n",
    "        gradient_list.extend([agents[info[\"id\"]].compute_gradient(parameters)])\n",
    "    return policy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}